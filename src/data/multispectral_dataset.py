"""
å¤šå…‰è°±æ•°æ®é›†åŠ è½½æ¨¡å— - ç›´æ¥å¤„ç†åŸå§‹å¤šå…‰è°±å›¾åƒ
ä¸ä½¿ç”¨ç™½ç‚¹é¢„å¤„ç†ï¼Œè®©ResNetç›´æ¥å­¦ä¹ å¤šå…‰è°±ç‰¹å¾
"""

import os
import torch
import numpy as np
from torch.utils.data import Dataset, DataLoader
from typing import Tuple, Optional, Dict, List
import scipy.io as sio
from pathlib import Path
import logging
from sklearn.model_selection import train_test_split
from .scene_split_utils import split_by_scene, analyze_scene_split
import torchvision.transforms as transforms
import random


class MultispectralDataset(Dataset):
    """
    å¤šå…‰è°±æ•°æ®é›†ç±» - ç›´æ¥å¤„ç†åŸå§‹å¤šå…‰è°±å›¾åƒ
    ä¸è¿›è¡Œç™½ç‚¹ç‰¹å¾æå–ï¼Œä¿ç•™å®Œæ•´çš„ç©ºé—´-å…‰è°±ä¿¡æ¯
    """
    
    def __init__(self,
                 data_dir: str,
                 csf_path: str,
                 mode: str = 'train',
                 train_split_ratio: float = 0.85,
                 random_seed: int = 42,
                 target_height: int = 132,
                 max_width: int = 400,
                 normalize_input: bool = True,
                 use_augmentation: bool = False,
                 augmentation_config: Dict = None,
                 preprocessing_strategy: str = "progressive",
                 use_scene_split: bool = False):
        """
        åˆå§‹åŒ–æ•°æ®é›†
        
        Args:
            data_dir: æ•°æ®ç›®å½•è·¯å¾„
            csf_path: ç›¸æœºå“åº”å‡½æ•°æ–‡ä»¶è·¯å¾„
            mode: 'train', 'val', æˆ– 'test'
            train_split_ratio: è®­ç»ƒé›†æ¯”ä¾‹
            random_seed: éšæœºç§å­
            target_height: ç›®æ ‡å›¾åƒé«˜åº¦
            normalize_input: æ˜¯å¦å½’ä¸€åŒ–è¾“å…¥
            use_augmentation: æ˜¯å¦ä½¿ç”¨æ•°æ®å¢å¼º
            augmentation_config: æ•°æ®å¢å¼ºé…ç½®
        """
        self.data_dir = Path(data_dir)
        self.csf_path = csf_path
        self.mode = mode
        self.random_seed = random_seed
        self.target_height = target_height
        self.max_width = max_width
        self.normalize_input = normalize_input
        self.use_augmentation = use_augmentation and mode == 'train'
        self.augmentation_config = augmentation_config or {}
        self.preprocessing_strategy = preprocessing_strategy
        self.use_scene_split = use_scene_split
        
        # åŠ è½½ç›¸æœºå“åº”å‡½æ•°
        self.csf = self._load_csf()
        
        # è·å–æ–‡ä»¶åˆ—è¡¨å¹¶åˆ’åˆ†æ•°æ®é›†
        self.file_paths = self._get_file_paths()
        
        # æ ¹æ®æ¨¡å¼åˆ’åˆ†æ•°æ®é›†
        if 'training' in str(data_dir):
            # è®­ç»ƒæ•°æ®ï¼šä»è®­ç»ƒæ•°æ®ä¸­è¿›ä¸€æ­¥åˆ’åˆ†è®­ç»ƒ/éªŒè¯
            if mode in ['train', 'val']:
                if use_scene_split:
                    # æŒ‰åœºæ™¯åˆ’åˆ†ï¼Œé¿å…æ•°æ®æ³„éœ²
                    logging.info(f"Using scene-based split to avoid data leakage")
                    train_files, val_files = split_by_scene(
                        self.file_paths,
                        train_ratio=train_split_ratio,
                        random_seed=random_seed
                    )
                    # åˆ†æå¹¶è®°å½•åˆ’åˆ†ç»Ÿè®¡
                    stats = analyze_scene_split(train_files, val_files)
                    logging.info(f"Scene split stats:")
                    logging.info(f"  Train: {stats['num_train_files']} files, {stats['num_train_scenes']} scenes")
                    logging.info(f"  Val: {stats['num_val_files']} files, {stats['num_val_scenes']} scenes")
                    if stats['has_overlap']:
                        logging.warning(f"âš ï¸ Data leakage detected! Overlap scenes: {stats['overlap_scenes']}")
                    else:
                        logging.info(f"âœ… No data leakage - scenes are properly separated")
                else:
                    # éšæœºåˆ’åˆ†ï¼ˆåŸå§‹æ–¹æ³•ï¼Œå¯èƒ½å¯¼è‡´æ•°æ®æ³„éœ²ï¼‰
                    logging.warning(f"Using random split - may cause data leakage if same scene appears in train and val")
                    train_files, val_files = train_test_split(
                        self.file_paths, 
                        train_size=train_split_ratio,
                        random_state=random_seed
                    )
                
                self.file_paths = train_files if mode == 'train' else val_files
        # æµ‹è¯•æ•°æ®ï¼šç›´æ¥ä½¿ç”¨æµ‹è¯•å›¾åƒ
        
        logging.info(f"Loaded {len(self.file_paths)} samples for {mode} mode")
        
        # è®¾ç½®æ•°æ®å¢å¼º
        if self.use_augmentation:
            self._setup_augmentation()
    
    def _load_csf(self) -> np.ndarray:
        """åŠ è½½ç›¸æœºå“åº”å‡½æ•°"""
        try:
            csf_data = sio.loadmat(self.csf_path)
            
            # å°è¯•ä¸åŒçš„é”®å
            for key in ['CRF', 'csf', 'sensitivity', 'camera_sensitivity']:
                if key in csf_data:
                    csf = np.array(csf_data[key], dtype=np.float32)
                    if csf.shape == (3, 33):
                        return csf[:, :31].T  # æˆªå–å‰31åˆ—å¹¶è½¬ç½®
                    elif csf.shape == (3, 31):
                        return csf.T
                    elif csf.shape == (31, 3):
                        return csf
            
            # å¦‚æœæ‰¾ä¸åˆ°æ ‡å‡†keyï¼Œå°è¯•æ‰¾åˆ°åˆé€‚å½¢çŠ¶çš„çŸ©é˜µ
            for key, value in csf_data.items():
                if isinstance(value, np.ndarray) and not key.startswith('__'):
                    if value.shape == (31, 3):
                        return value.astype(np.float32)
                    elif value.shape == (3, 31):
                        return value.T.astype(np.float32)
                    elif value.shape == (3, 33):
                        return value[:, :31].T.astype(np.float32)
            
            raise ValueError(f"Could not find CSF matrix in {self.csf_path}")
            
        except Exception as e:
            logging.error(f"Failed to load CSF from {self.csf_path}: {e}")
            return self._create_default_csf()
    
    def _create_default_csf(self) -> np.ndarray:
        """åˆ›å»ºé»˜è®¤çš„ç›¸æœºå“åº”å‡½æ•°"""
        logging.warning("Using default CSF matrix")
        csf = np.zeros((31, 3), dtype=np.float32)
        csf[20:31, 0] = np.linspace(0.1, 1.0, 11)  # R
        csf[10:25, 1] = np.concatenate([np.linspace(0.1, 1.0, 8), np.linspace(1.0, 0.1, 7)])  # G
        csf[0:15, 2] = np.linspace(1.0, 0.1, 15)  # B
        return csf
    
    def _get_file_paths(self) -> List[Path]:
        """è·å–æ‰€æœ‰.matæ–‡ä»¶è·¯å¾„"""
        file_paths = []
        if self.data_dir.is_dir():
            for file_path in self.data_dir.glob("*.mat"):
                file_paths.append(file_path)
        
        file_paths.sort()  # ç¡®ä¿é¡ºåºä¸€è‡´
        return file_paths
    
    def _setup_augmentation(self):
        """è®¾ç½®æ•°æ®å¢å¼º"""
        aug_config = self.augmentation_config
        
        # ç©ºé—´å¢å¼º
        self.random_crop = aug_config.get('random_crop', False)
        self.crop_size = aug_config.get('crop_size', [120, 160])
        self.horizontal_flip = aug_config.get('horizontal_flip', False)
        self.vertical_flip = aug_config.get('vertical_flip', False)
        
        # å…‰è°±å¢å¼º
        self.spectral_noise_std = aug_config.get('spectral_noise_std', 0.01)
        self.spectral_shift_range = aug_config.get('spectral_shift_range', 0.02)
        
        # ç…§åº¦å¢å¼º
        self.illuminant_variation = aug_config.get('illuminant_variation', False)
        self.illuminant_noise_std = aug_config.get('illuminant_noise_std', 0.05)
    
    def _resize_multispectral(self, ms_data: np.ndarray) -> np.ndarray:
        """æ™ºèƒ½å¤šå…‰è°±å›¾åƒå°ºå¯¸è°ƒæ•´ - æ·±åº¦å­¦ä¹ ä¼˜åŒ–ç‰ˆæœ¬"""
        H_orig, W_orig, C = ms_data.shape
        
        # æ ¹æ®é…ç½®é€‰æ‹©é¢„å¤„ç†ç­–ç•¥
        if self.preprocessing_strategy == "progressive":
            return self._progressive_downsample(ms_data)
        elif self.preprocessing_strategy == "two_stage":
            return self._two_stage_downsample(ms_data)
        else:  # "standard"
            return self._standard_resize(ms_data)
    
    def _progressive_downsample(self, ms_data: np.ndarray) -> np.ndarray:
        """
        æ™ºèƒ½æ¸è¿›å¼ä¸‹é‡‡æ · - å€Ÿé‰´WPæˆåŠŸç»éªŒï¼Œæå–ä»£è¡¨æ€§ç‰¹å¾
        ä»1912Ã—WÃ—31å·¨å¤§ä¿¡æ¯ä¸­æå–å…³é”®å…‰ç…§ä¿¡æ¯
        """
        from scipy import ndimage
        H_orig, W_orig, C = ms_data.shape
        
        # ç¬¬ä¸€æ­¥ï¼šæå–ç©ºé—´ä»£è¡¨æ€§åŒºåŸŸ (å€Ÿé‰´WPæ€æƒ³)
        # WPæˆåŠŸçš„åŸå› ï¼šæ‰¾åˆ°æœ€äº®åŒºåŸŸ = å…‰æºä¿¡æ¯æœ€ä¸°å¯Œçš„åŒºåŸŸ
        ms_data = self._extract_informative_regions(ms_data)
        
        # ç¬¬äºŒæ­¥ï¼šå¤šé˜¶æ®µä¸‹é‡‡æ ·ä¿ç•™ç»†èŠ‚
        stages = []
        current_h = ms_data.shape[0]  # æ›´æ–°åçš„é«˜åº¦
        target_h = self.target_height  # 132
        
        # è®¡ç®—ä¸‹é‡‡æ ·é˜¶æ®µ
        while current_h > target_h * 2:
            current_h = current_h // 2
            stages.append(current_h)
        stages.append(target_h)
        
        # é€é˜¶æ®µä¸‹é‡‡æ ·
        current_data = ms_data
        for stage_h in stages:
            stage_w = int(current_data.shape[1] * (stage_h / current_data.shape[0]))
            stage_w = min(stage_w, self.max_width)  # é™åˆ¶æœ€å¤§å®½åº¦
            
            # å¯¹æ¯ä¸ªé€šé“è¿›è¡Œé«˜è´¨é‡resize
            resized_channels = []
            for c in range(C):
                channel_data = current_data[:, :, c]
                # ä½¿ç”¨åŒä¸‰æ¬¡æ’å€¼è·å¾—æ›´å¥½çš„è´¨é‡
                resized_channel = ndimage.zoom(
                    channel_data,
                    (stage_h / current_data.shape[0], stage_w / current_data.shape[1]),
                    order=3,  # åŒä¸‰æ¬¡æ’å€¼
                    prefilter=True  # é¢„æ»¤æ³¢å‡å°‘æ··å 
                )
                resized_channels.append(resized_channel)
            
            current_data = np.stack(resized_channels, axis=2)
        
        return current_data
    
    def _extract_informative_regions(self, ms_data: np.ndarray) -> np.ndarray:
        """
        æå–ä¿¡æ¯ä¸°å¯Œçš„åŒºåŸŸ - å€Ÿé‰´WPç®—æ³•çš„æˆåŠŸæ€è·¯
        WPæˆåŠŸçš„æ ¸å¿ƒï¼šæ‰¾åˆ°æœ€äº®åŒºåŸŸ = å…‰æºä¿¡æ¯æœ€é›†ä¸­çš„åŒºåŸŸ
        """
        H, W, C = ms_data.shape
        
        # ç­–ç•¥1ï¼šåŸºäºäº®åº¦çš„åŒºåŸŸæå– (ç±»ä¼¼WPä½†ä¿ç•™ç©ºé—´ä¿¡æ¯)
        # è®¡ç®—æ¯ä¸ªåƒç´ çš„æ€»äº®åº¦
        brightness = np.sum(ms_data, axis=2)  # [H, W]
        
        # æ‰¾åˆ°äº®åº¦å‰20%çš„åŒºåŸŸ (æ¯”WPçš„å•ç‚¹maxæ›´ä¸°å¯Œ)
        brightness_threshold = np.percentile(brightness, 80)
        bright_mask = brightness >= brightness_threshold
        
        # ç­–ç•¥2ï¼šä¿ç•™é«˜å¯¹æ¯”åº¦åŒºåŸŸ (å…‰ç…§å˜åŒ–æ˜æ˜¾çš„åŒºåŸŸ)
        # è®¡ç®—æ¯ä¸ªåƒç´ çš„å…‰è°±å˜åŒ–
        spectral_variance = np.var(ms_data, axis=2)  # [H, W]
        variance_threshold = np.percentile(spectral_variance, 75)
        variance_mask = spectral_variance >= variance_threshold
        
        # ç­–ç•¥3ï¼šç»“åˆäº®åº¦å’Œå¯¹æ¯”åº¦ä¿¡æ¯
        informative_mask = bright_mask | variance_mask
        
        # å¦‚æœä¿¡æ¯åŒºåŸŸå¤ªå°‘ï¼Œæ”¾å®½æ¡ä»¶
        if np.sum(informative_mask) < H * W * 0.3:
            brightness_threshold = np.percentile(brightness, 70)
            variance_threshold = np.percentile(spectral_variance, 60)
            bright_mask = brightness >= brightness_threshold
            variance_mask = spectral_variance >= variance_threshold
            informative_mask = bright_mask | variance_mask
        
        # æå–ä¿¡æ¯ä¸°å¯Œçš„è¡Œ
        informative_rows = np.any(informative_mask, axis=1)
        if np.sum(informative_rows) < H * 0.4:  # è‡³å°‘ä¿ç•™40%çš„è¡Œ
            # å¦‚æœä¿¡æ¯è¡Œå¤ªå°‘ï¼Œä¿ç•™äº®åº¦æœ€é«˜çš„è¡Œ
            row_brightness = np.mean(brightness, axis=1)
            top_rows = np.argsort(row_brightness)[-int(H * 0.4):]
            informative_rows = np.zeros(H, dtype=bool)
            informative_rows[top_rows] = True
        
        # æå–é€‰ä¸­çš„è¡Œï¼Œå¤§å¹…å‡å°‘æ•°æ®é‡
        selected_ms_data = ms_data[informative_rows, :, :]
        
        # è¿›ä¸€æ­¥ä¼˜åŒ–ï¼šå¦‚æœè¿˜æ˜¯å¤ªå¤§ï¼Œå†æ¬¡å‹ç¼©
        new_H = selected_ms_data.shape[0]
        if new_H > 800:  # å¦‚æœè¿˜æ˜¯å¤ªå¤§
            # å‡åŒ€é‡‡æ ·åˆ°åˆç†å¤§å°
            step = new_H // 600
            selected_ms_data = selected_ms_data[::step, :, :]
        
        return selected_ms_data
    
    def _two_stage_downsample(self, ms_data: np.ndarray) -> np.ndarray:
        """åŒé˜¶æ®µä¸‹é‡‡æ · - å¹³è¡¡è´¨é‡å’Œæ•ˆç‡"""
        from scipy import ndimage
        H_orig, W_orig, C = ms_data.shape
        
        # ç¬¬ä¸€é˜¶æ®µ: ä¸‹é‡‡æ ·åˆ°ä¸­ç­‰å°ºå¯¸
        mid_h = max(H_orig // 3, self.target_height * 2)
        mid_w = int(W_orig * (mid_h / H_orig))
        mid_w = min(mid_w, self.max_width)
        
        # ç¬¬äºŒé˜¶æ®µ: ä¸‹é‡‡æ ·åˆ°ç›®æ ‡å°ºå¯¸
        target_h = self.target_height
        target_w = int(mid_w * (target_h / mid_h))
        
        resized_channels = []
        for c in range(C):
            channel_data = ms_data[:, :, c]
            
            # ç¬¬ä¸€é˜¶æ®µ: ä½¿ç”¨é«˜æ–¯æ»¤æ³¢+ä¸‹é‡‡æ ·
            mid_channel = ndimage.gaussian_filter(channel_data, sigma=1.0)
            mid_channel = ndimage.zoom(mid_channel, (mid_h / H_orig, mid_w / W_orig), order=1)
            
            # ç¬¬äºŒé˜¶æ®µ: ç²¾ç»†è°ƒæ•´åˆ°ç›®æ ‡å°ºå¯¸
            final_channel = ndimage.zoom(mid_channel, (target_h / mid_h, target_w / mid_w), order=3)
            
            resized_channels.append(final_channel)
        
        return np.stack(resized_channels, axis=2)
    
    def _standard_resize(self, ms_data: np.ndarray) -> np.ndarray:
        """æ ‡å‡†resize - ç”¨äºå°å›¾åƒ"""
        from scipy import ndimage
        H_orig, W_orig, C = ms_data.shape
        
        target_h = self.target_height
        calculated_w = int(W_orig * (target_h / H_orig))
        target_w = min(calculated_w, self.max_width)
        
        resized_channels = []
        for c in range(C):
            channel_data = ms_data[:, :, c]
            resized_channel = ndimage.zoom(
                channel_data,
                (target_h / H_orig, target_w / W_orig),
                order=1  # åŒçº¿æ€§æ’å€¼
            )
            resized_channels.append(resized_channel)
        
        return np.stack(resized_channels, axis=2)
    
    def _resize_to_target(self, ms_data: np.ndarray, target_size: list) -> np.ndarray:
        """è°ƒæ•´å›¾åƒåˆ°ç›®æ ‡å°ºå¯¸"""
        H_orig, W_orig, C = ms_data.shape
        target_h, target_w = target_size
        
        # å¯¹æ¯ä¸ªé€šé“åˆ†åˆ«è¿›è¡Œresize
        resized_channels = []
        for c in range(C):
            from scipy import ndimage
            channel_data = ms_data[:, :, c]
            resized_channel = ndimage.zoom(
                channel_data, 
                (target_h / H_orig, target_w / W_orig), 
                order=1  # åŒçº¿æ€§æ’å€¼
            )
            resized_channels.append(resized_channel)
        
        return np.stack(resized_channels, axis=2)
    
    def _apply_spatial_augmentation(self, ms_data: np.ndarray) -> np.ndarray:
        """åº”ç”¨ç©ºé—´æ•°æ®å¢å¼º"""
        H, W, C = ms_data.shape
        
        # éšæœºè£å‰ª - ç¡®ä¿è£å‰ªåå°ºå¯¸ä¸€è‡´
        if self.random_crop and H > self.crop_size[0] and W > self.crop_size[1]:
            top = random.randint(0, H - self.crop_size[0])
            left = random.randint(0, W - self.crop_size[1])
            ms_data = ms_data[top:top+self.crop_size[0], left:left+self.crop_size[1], :]
        elif self.random_crop:
            # å¦‚æœå›¾åƒå°äºè£å‰ªå°ºå¯¸ï¼Œç›´æ¥resizeåˆ°è£å‰ªå°ºå¯¸
            ms_data = self._resize_to_target(ms_data, self.crop_size)
        
        # æ°´å¹³ç¿»è½¬
        if self.horizontal_flip and random.random() > 0.5:
            ms_data = np.flip(ms_data, axis=1)
        
        # å‚ç›´ç¿»è½¬
        if self.vertical_flip and random.random() > 0.5:
            ms_data = np.flip(ms_data, axis=0)
        
        return ms_data.copy()  # ç¡®ä¿å†…å­˜è¿ç»­
    
    def _apply_spectral_augmentation(self, ms_data: np.ndarray) -> np.ndarray:
        """åº”ç”¨å…‰è°±æ•°æ®å¢å¼º"""
        # å…‰è°±å™ªå£°
        if self.spectral_noise_std > 0:
            noise = np.random.normal(0, self.spectral_noise_std, ms_data.shape)
            ms_data = ms_data + noise
        
        # å…‰è°±åç§»
        if self.spectral_shift_range > 0:
            shift = np.random.uniform(-self.spectral_shift_range, 
                                    self.spectral_shift_range, 
                                    ms_data.shape[-1])
            ms_data = ms_data * (1 + shift)
        
        return ms_data
    
    def _apply_illuminant_augmentation(self, illumination: np.ndarray) -> np.ndarray:
        """åº”ç”¨ç…§åº¦æ•°æ®å¢å¼º"""
        if self.illuminant_variation:
            # æ·»åŠ ç…§åº¦å™ªå£°
            if self.illuminant_noise_std > 0:
                noise = np.random.normal(0, self.illuminant_noise_std, illumination.shape)
                illumination = illumination * (1 + noise)
        
        return illumination
    
    def __len__(self) -> int:
        return len(self.file_paths)
    
    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        """
        è·å–æ•°æ®æ ·æœ¬
        
        Returns:
            åŒ…å«ä»¥ä¸‹é”®çš„å­—å…¸:
            - 'multispectral': å¤šå…‰è°±æ•°æ® [31, H, W]
            - 'illumination_gt': åœ°é¢çœŸå€¼å…‰ç…§ [31]
            - 'filename': æ–‡ä»¶å
        """
        file_path = self.file_paths[idx]
        
        try:
            # åŠ è½½.matæ–‡ä»¶
            mat_data = sio.loadmat(str(file_path))
            
            # æå–å¤šå…‰è°±æ•°æ®
            if 'tensor' in mat_data:
                ms_data = np.array(mat_data['tensor'], dtype=np.float32)
            elif 'img' in mat_data:
                ms_data = np.array(mat_data['img'], dtype=np.float32)
            else:
                raise ValueError(f"Could not find multispectral data in {file_path}")
            
            # æå–åœ°é¢çœŸå€¼å…‰ç…§
            if 'illumination' in mat_data:
                illumination_gt = np.array(mat_data['illumination'], dtype=np.float32)
            elif 'illum' in mat_data:
                illumination_gt = np.array(mat_data['illum'], dtype=np.float32)
            else:
                raise ValueError(f"Could not find illumination data in {file_path}")
            
            # éªŒè¯æ•°æ®å½¢çŠ¶
            if len(ms_data.shape) != 3 or ms_data.shape[2] != 31:
                raise ValueError(f"Invalid multispectral data shape: {ms_data.shape}")
            
            # ç¡®ä¿illumination_gtæ˜¯1Dæ•°ç»„
            if illumination_gt.ndim > 1:
                illumination_gt = illumination_gt.flatten()
            
            if illumination_gt.shape[0] != 31:
                raise ValueError(f"Invalid illumination shape: {illumination_gt.shape}")
            
            # è°ƒæ•´å›¾åƒå°ºå¯¸
            ms_data = self._resize_multispectral(ms_data)
            
            # æ•°æ®æ¸…ç†ï¼šç¡®ä¿æœ‰é™å€¼
            ms_data = np.nan_to_num(ms_data, nan=0.0, posinf=1.0, neginf=0.0)
            illumination_gt = np.nan_to_num(illumination_gt, nan=0.0, posinf=1.0, neginf=0.0)
            
            # ç¡®ä¿éè´Ÿå€¼
            ms_data = np.clip(ms_data, 0, None)
            illumination_gt = np.clip(illumination_gt, 0, None)
            
            # æ•°æ®å¢å¼º
            if self.use_augmentation:
                ms_data = self._apply_spatial_augmentation(ms_data)
                ms_data = self._apply_spectral_augmentation(ms_data)
                illumination_gt = self._apply_illuminant_augmentation(illumination_gt)
            
            # ç¡®ä¿å°ºå¯¸ä¸€è‡´ - å¦‚æœæ²¡æœ‰è¿›è¡Œéšæœºè£å‰ªæˆ–è£å‰ªåå°ºå¯¸ä¸å¯¹ï¼Œå¼ºåˆ¶resize
            current_h, current_w = ms_data.shape[:2]
            if self.use_augmentation and hasattr(self, 'crop_size'):
                target_h, target_w = self.crop_size
                if current_h != target_h or current_w != target_w:
                    ms_data = self._resize_to_target(ms_data, self.crop_size)
            else:
                # éå¢å¼ºæ¨¡å¼ï¼šç»Ÿä¸€resizeåˆ°ç›®æ ‡é«˜åº¦ï¼Œä¿æŒå®½é«˜æ¯”
                if current_h != self.target_height:
                    target_width = int(current_w * (self.target_height / current_h))
                    ms_data = self._resize_to_target(ms_data, [self.target_height, target_width])
            
            # è¾“å…¥å½’ä¸€åŒ–
            if self.normalize_input:
                # æŒ‰é€šé“å½’ä¸€åŒ–
                for c in range(ms_data.shape[2]):
                    channel_data = ms_data[:, :, c]
                    if channel_data.max() > channel_data.min():
                        ms_data[:, :, c] = (channel_data - channel_data.min()) / (channel_data.max() - channel_data.min())
            
            # è½¬æ¢ä¸ºtorchå¼ é‡å¹¶è°ƒæ•´ç»´åº¦é¡ºåº [H, W, C] -> [C, H, W]
            ms_tensor = torch.from_numpy(ms_data).float().permute(2, 0, 1)
            illumination_tensor = torch.from_numpy(illumination_gt).float()
            
            return {
                'multispectral': ms_tensor,
                'illumination_gt': illumination_tensor,
                'filename': file_path.name
            }
            
        except Exception as e:
            logging.error(f"Error loading {file_path}: {e}")
            # è¿”å›é›¶å¡«å……çš„æ•°æ®ä»¥é¿å…è®­ç»ƒä¸­æ–­
            return {
                'multispectral': torch.zeros(31, self.target_height, 
                                           int(self.target_height * 1.33)),  # 4:3 æ¯”ä¾‹
                'illumination_gt': torch.ones(31) / np.sqrt(31),  # å½’ä¸€åŒ–çš„å‡åŒ€å…‰ç…§
                'filename': file_path.name
            }
    
    def get_csf(self) -> torch.Tensor:
        """è·å–ç›¸æœºå“åº”å‡½æ•°å¼ é‡"""
        return torch.from_numpy(self.csf).float()


def multispectral_collate_fn(batch):
    """
    è‡ªå®šä¹‰collateå‡½æ•°ï¼Œå¤„ç†ä¸åŒå°ºå¯¸çš„å¤šå…‰è°±å›¾åƒ
    ä½¿ç”¨è¾¹ç¼˜å¤åˆ¶paddingï¼Œæ›´é€‚åˆå…‰è°±æ•°æ®ï¼ˆé¿å…å¼•å…¥å‡çš„0è¾¹ç•Œï¼‰
    """
    import torch.nn.functional as F
    
    # è·å–æ‰¹æ¬¡ä¸­çš„æœ€å¤§å°ºå¯¸
    max_h = max([item['multispectral'].shape[1] for item in batch])
    max_w = max([item['multispectral'].shape[2] for item in batch])
    
    padded_images = []
    illumination_gts = []
    filenames = []
    
    for item in batch:
        ms_tensor = item['multispectral']  # [C, H, W]
        current_h, current_w = ms_tensor.shape[1], ms_tensor.shape[2]
        
        # è®¡ç®—éœ€è¦paddingçš„é‡
        pad_bottom = max_h - current_h
        pad_right = max_w - current_w
        
        if pad_bottom > 0 or pad_right > 0:
            # ğŸ”§ æ”¹è¿›ï¼šä½¿ç”¨replicate paddingä»£æ›¿zero padding
            # mode='replicate': å¤åˆ¶è¾¹ç¼˜åƒç´ å€¼ï¼Œå¯¹å…‰è°±æ•°æ®æ›´è‡ªç„¶
            # paddingé¡ºåº: (left, right, top, bottom)
            padded = F.pad(ms_tensor, 
                          (0, pad_right, 0, pad_bottom), 
                          mode='replicate')
        else:
            padded = ms_tensor
        
        padded_images.append(padded)
        illumination_gts.append(item['illumination_gt'])
        filenames.append(item['filename'])
    
    return {
        'multispectral': torch.stack(padded_images),
        'illumination_gt': torch.stack(illumination_gts),
        'filename': filenames
    }


def create_multispectral_dataloaders(train_dir: str,
                                   test_dir: str,
                                   csf_path: str,
                                   config: Dict,
                                   batch_size: int = 6,
                                   train_split_ratio: float = 0.85,
                                   num_workers: int = 0,
                                   random_seed: int = 42,
                                   persistent_workers: bool = False,
                                   prefetch_factor: int = 2) -> Tuple[DataLoader, DataLoader, DataLoader]:
    """
    åˆ›å»ºå¤šå…‰è°±æ•°æ®åŠ è½½å™¨
    
    Args:
        train_dir: è®­ç»ƒæ•°æ®ç›®å½•
        test_dir: æµ‹è¯•æ•°æ®ç›®å½•
        csf_path: CSFæ–‡ä»¶è·¯å¾„
        config: é…ç½®å­—å…¸
        batch_size: æ‰¹æ¬¡å¤§å°
        train_split_ratio: è®­ç»ƒéªŒè¯åˆ’åˆ†æ¯”ä¾‹
        num_workers: æ•°æ®åŠ è½½å·¥ä½œè¿›ç¨‹æ•°
        random_seed: éšæœºç§å­
    
    Returns:
        (train_loader, val_loader, test_loader)
    """
    
    # è·å–é…ç½®
    data_config = config.get('data', {})
    training_config = config.get('training', {})
    
    target_height = data_config.get('target_height', 132)
    max_width = data_config.get('max_width', 400)
    normalize_input = data_config.get('normalize_input', True)
    preprocessing_strategy = data_config.get('preprocessing_strategy', 'progressive')
    use_augmentation = training_config.get('use_augmentation', False)
    augmentation_config = training_config.get('augmentation', {})
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = MultispectralDataset(
        train_dir, csf_path, mode='train', 
        train_split_ratio=train_split_ratio, 
        random_seed=random_seed,
        target_height=target_height,
        max_width=max_width,
        normalize_input=normalize_input,
        use_augmentation=use_augmentation,
        augmentation_config=augmentation_config,
        preprocessing_strategy=preprocessing_strategy
    )
    
    val_dataset = MultispectralDataset(
        train_dir, csf_path, mode='val',
        train_split_ratio=train_split_ratio, 
        random_seed=random_seed,
        target_height=target_height,
        max_width=max_width,
        normalize_input=normalize_input,
        use_augmentation=False,  # éªŒè¯æ—¶ä¸ä½¿ç”¨æ•°æ®å¢å¼º
        preprocessing_strategy=preprocessing_strategy
    )
    
    test_dataset = MultispectralDataset(
        test_dir, csf_path, mode='test',
        random_seed=random_seed,
        target_height=target_height,
        max_width=max_width,
        normalize_input=normalize_input,
        use_augmentation=False,  # æµ‹è¯•æ—¶ä¸ä½¿ç”¨æ•°æ®å¢å¼º
        preprocessing_strategy=preprocessing_strategy
    )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼Œä½¿ç”¨è‡ªå®šä¹‰collateå‡½æ•°
    # persistent_workerså’Œprefetch_factorä»…åœ¨num_workers > 0æ—¶ç”Ÿæ•ˆ
    dataloader_kwargs = {
        'batch_size': batch_size,
        'num_workers': num_workers,
        'pin_memory': torch.cuda.is_available(),
        'collate_fn': multispectral_collate_fn
    }
    
    # ä»…åœ¨æœ‰workersæ—¶æ·»åŠ persistent_workerså’Œprefetch_factor
    if num_workers > 0:
        dataloader_kwargs['persistent_workers'] = persistent_workers
        dataloader_kwargs['prefetch_factor'] = prefetch_factor
    
    train_loader = DataLoader(
        train_dataset, 
        shuffle=True,
        drop_last=True,  # è®­ç»ƒæ—¶ä¸¢å¼ƒæœ€åä¸€ä¸ªä¸å®Œæ•´çš„batch
        **dataloader_kwargs
    )
    
    val_loader = DataLoader(
        val_dataset,
        shuffle=False,
        drop_last=False,
        **dataloader_kwargs
    )
    
    test_loader = DataLoader(
        test_dataset,
        shuffle=False,
        drop_last=False,
        **dataloader_kwargs
    )
    
    return train_loader, val_loader, test_loader


if __name__ == "__main__":
    # æµ‹è¯•æ•°æ®é›†åŠ è½½
    logging.basicConfig(level=logging.INFO)
    
    train_dir = "../data/dataset/training/mat_norm"
    test_dir = "../data/dataset/testing/mat_norm"
    csf_path = "../data/Canon_1D_Mark_III.mat"
    
    config = {
        'data': {
            'target_height': 132,
            'normalize_input': True
        },
        'training': {
            'use_augmentation': True,
            'augmentation': {
                'random_crop': True,
                'crop_size': [120, 160],
                'horizontal_flip': True,
                'spectral_noise_std': 0.01
            }
        }
    }
    
    try:
        train_loader, val_loader, test_loader = create_multispectral_dataloaders(
            train_dir, test_dir, csf_path, config, batch_size=4
        )
        
        print(f"Train samples: {len(train_loader.dataset)}")
        print(f"Val samples: {len(val_loader.dataset)}")
        print(f"Test samples: {len(test_loader.dataset)}")
        
        # æµ‹è¯•åŠ è½½ä¸€ä¸ªæ‰¹æ¬¡
        for batch in train_loader:
            print(f"Multispectral shape: {batch['multispectral'].shape}")
            print(f"Illumination GT shape: {batch['illumination_gt'].shape}")
            print(f"Value ranges: MS [{batch['multispectral'].min():.3f}, {batch['multispectral'].max():.3f}]")
            break
            
    except Exception as e:
        print(f"Dataset test failed: {e}")
